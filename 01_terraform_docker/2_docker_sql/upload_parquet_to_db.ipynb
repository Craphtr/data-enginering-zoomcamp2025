{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style = \"background-color: black\">,\n",
    "        <p><b><font size=\"+4\" color=\"orange\">Preparing Data for Loading to Postgres16</font></b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style = \"background-color: black\">,\n",
    "        <p><b><font size=\"+2\" color=\"orange\">Extract, Clean & Load data from parquet to Postgres16</font></b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476386\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386</td>\n",
       "      <td>476386</td>\n",
       "      <td>387007.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>387007.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>476386.000000</td>\n",
       "      <td>387007.000000</td>\n",
       "      <td>387005.000000</td>\n",
       "      <td>387007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.864746</td>\n",
       "      <td>2019-10-16 10:39:51.805003008</td>\n",
       "      <td>2019-10-16 11:01:52.574901248</td>\n",
       "      <td>1.102104</td>\n",
       "      <td>108.789746</td>\n",
       "      <td>129.697575</td>\n",
       "      <td>1.308302</td>\n",
       "      <td>3.543614</td>\n",
       "      <td>15.782716</td>\n",
       "      <td>0.844550</td>\n",
       "      <td>0.486164</td>\n",
       "      <td>0.983024</td>\n",
       "      <td>0.317710</td>\n",
       "      <td>0.240391</td>\n",
       "      <td>18.986092</td>\n",
       "      <td>1.454666</td>\n",
       "      <td>1.023294</td>\n",
       "      <td>0.451301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2008-10-21 15:52:05</td>\n",
       "      <td>2008-10-21 15:54:26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.930000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-80.800000</td>\n",
       "      <td>-12.500000</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2019-10-08 16:37:00.750000128</td>\n",
       "      <td>2019-10-08 16:59:14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2019-10-16 16:46:56.500000</td>\n",
       "      <td>2019-10-16 17:11:33.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>14.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2019-10-24 10:05:55</td>\n",
       "      <td>2019-10-24 10:28:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.270000</td>\n",
       "      <td>20.730000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>24.620000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2019-11-13 08:46:52</td>\n",
       "      <td>2019-11-13 08:58:26</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>515.890000</td>\n",
       "      <td>2877.500000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>158.520000</td>\n",
       "      <td>935.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2878.300000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.341995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727587</td>\n",
       "      <td>71.420448</td>\n",
       "      <td>76.351002</td>\n",
       "      <td>0.967869</td>\n",
       "      <td>4.168409</td>\n",
       "      <td>14.100716</td>\n",
       "      <td>1.135181</td>\n",
       "      <td>0.089725</td>\n",
       "      <td>1.981928</td>\n",
       "      <td>2.177628</td>\n",
       "      <td>0.121327</td>\n",
       "      <td>15.621042</td>\n",
       "      <td>0.522706</td>\n",
       "      <td>0.150837</td>\n",
       "      <td>1.018531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            VendorID           lpep_pickup_datetime  \\\n",
       "count  476386.000000                         476386   \n",
       "mean        1.864746  2019-10-16 10:39:51.805003008   \n",
       "min         1.000000            2008-10-21 15:52:05   \n",
       "25%         2.000000  2019-10-08 16:37:00.750000128   \n",
       "50%         2.000000     2019-10-16 16:46:56.500000   \n",
       "75%         2.000000            2019-10-24 10:05:55   \n",
       "max         2.000000            2019-11-13 08:46:52   \n",
       "std         0.341995                            NaN   \n",
       "\n",
       "               lpep_dropoff_datetime     RatecodeID   PULocationID  \\\n",
       "count                         476386  387007.000000  476386.000000   \n",
       "mean   2019-10-16 11:01:52.574901248       1.102104     108.789746   \n",
       "min              2008-10-21 15:54:26       1.000000       1.000000   \n",
       "25%              2019-10-08 16:59:14       1.000000      55.000000   \n",
       "50%       2019-10-16 17:11:33.500000       1.000000      82.000000   \n",
       "75%              2019-10-24 10:28:00       1.000000     166.000000   \n",
       "max              2019-11-13 08:58:26      99.000000     265.000000   \n",
       "std                              NaN       0.727587      71.420448   \n",
       "\n",
       "        DOLocationID  passenger_count  trip_distance    fare_amount  \\\n",
       "count  476386.000000    387007.000000  476386.000000  476386.000000   \n",
       "mean      129.697575         1.308302       3.543614      15.782716   \n",
       "min         1.000000         0.000000      -6.930000    -200.000000   \n",
       "25%        65.000000         1.000000       1.100000       7.000000   \n",
       "50%       129.000000         1.000000       2.070000      11.500000   \n",
       "75%       193.000000         1.000000       4.270000      20.730000   \n",
       "max       265.000000         9.000000     515.890000    2877.500000   \n",
       "std        76.351002         0.967869       4.168409      14.100716   \n",
       "\n",
       "               extra        mta_tax     tip_amount   tolls_amount  \\\n",
       "count  476386.000000  476386.000000  476386.000000  476386.000000   \n",
       "mean        0.844550       0.486164       0.983024       0.317710   \n",
       "min        -4.500000      -0.500000     -80.800000     -12.500000   \n",
       "25%         0.000000       0.500000       0.000000       0.000000   \n",
       "50%         0.500000       0.500000       0.000000       0.000000   \n",
       "75%         1.000000       0.500000       1.650000       0.000000   \n",
       "max         8.250000       0.500000     158.520000     935.500000   \n",
       "std         1.135181       0.089725       1.981928       2.177628   \n",
       "\n",
       "       improvement_surcharge   total_amount   payment_type      trip_type  \\\n",
       "count          476386.000000  476386.000000  387007.000000  387005.000000   \n",
       "mean                0.240391      18.986092       1.454666       1.023294   \n",
       "min                -0.300000    -200.000000       1.000000       1.000000   \n",
       "25%                 0.300000       9.000000       1.000000       1.000000   \n",
       "50%                 0.300000      14.160000       1.000000       1.000000   \n",
       "75%                 0.300000      24.620000       2.000000       1.000000   \n",
       "max                 0.300000    2878.300000       5.000000       2.000000   \n",
       "std                 0.121327      15.621042       0.522706       0.150837   \n",
       "\n",
       "       congestion_surcharge  \n",
       "count         387007.000000  \n",
       "mean               0.451301  \n",
       "min               -2.750000  \n",
       "25%                0.000000  \n",
       "50%                0.000000  \n",
       "75%                0.000000  \n",
       "max                2.750000  \n",
       "std                1.018531  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "ny_data_parquet = pq.ParquetFile(\"./ny_taxi_postgres_data/green_tripdata_2019-10.parquet\")\n",
    "\n",
    "ny_data_df = ny_data_parquet.read().to_pandas()\n",
    "print(len(ny_data_df))\n",
    "ny_data_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Longest trip occurred on which date__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386795   2019-10-31 23:23:41\n",
       "Name: lpep_pickup_datetime, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_data_df.lpep_pickup_datetime[ny_data_df['trip_distance'] == ny_data_df['trip_distance'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compute the number of fields with Negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount              1388\n",
       "extra                     560\n",
       "mta_tax                  1262\n",
       "tip_amount                 19\n",
       "tolls_amount                1\n",
       "ehail_fee                   0\n",
       "improvement_surcharge    1034\n",
       "total_amount             1388\n",
       "payment_type                0\n",
       "trip_type                   0\n",
       "congestion_surcharge        6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ny_data_df.loc[:,'fare_amount':'congestion_surcharge']<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223196</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-18 14:28:24</td>\n",
       "      <td>2019-10-18 14:28:34</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66474</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-05 20:17:37</td>\n",
       "      <td>2019-10-05 20:20:06</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-4.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369089</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-30 16:48:43</td>\n",
       "      <td>2019-10-30 16:58:22</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-7.50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-9.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145241</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-12 02:12:56</td>\n",
       "      <td>2019-10-12 02:13:01</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-3.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443491</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-22 10:29:10</td>\n",
       "      <td>2019-10-22 10:30:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-29.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-30.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419948</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-14 07:42:10</td>\n",
       "      <td>2019-10-14 07:42:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-17.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-18.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392578</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-03 09:46:10</td>\n",
       "      <td>2019-10-03 09:46:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-22.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406595</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-09 08:16:10</td>\n",
       "      <td>2019-10-09 08:16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-16.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37189</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-03 19:16:17</td>\n",
       "      <td>2019-10-03 19:18:46</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>-3.50</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-5.30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452691</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-24 15:16:10</td>\n",
       "      <td>2019-10-24 15:16:00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-33.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VendorID lpep_pickup_datetime lpep_dropoff_datetime  \\\n",
       "223196         2  2019-10-18 14:28:24   2019-10-18 14:28:34   \n",
       "66474          2  2019-10-05 20:17:37   2019-10-05 20:20:06   \n",
       "369089         2  2019-10-30 16:48:43   2019-10-30 16:58:22   \n",
       "145241         2  2019-10-12 02:12:56   2019-10-12 02:13:01   \n",
       "443491         2  2019-10-22 10:29:10   2019-10-22 10:30:00   \n",
       "419948         2  2019-10-14 07:42:10   2019-10-14 07:42:00   \n",
       "392578         2  2019-10-03 09:46:10   2019-10-03 09:46:00   \n",
       "406595         2  2019-10-09 08:16:10   2019-10-09 08:16:00   \n",
       "37189          2  2019-10-03 19:16:17   2019-10-03 19:18:46   \n",
       "452691         2  2019-10-24 15:16:10   2019-10-24 15:16:00   \n",
       "\n",
       "       store_and_fwd_flag  RatecodeID  PULocationID  DOLocationID  \\\n",
       "223196                  N         1.0            72           264   \n",
       "66474                   N         1.0             7             7   \n",
       "369089                  N         1.0            41            74   \n",
       "145241                  N         1.0           244           244   \n",
       "443491               None         NaN           188           188   \n",
       "419948               None         NaN            61           264   \n",
       "392578               None         NaN            80           264   \n",
       "406595               None         NaN            97            97   \n",
       "37189                   N         1.0           244           244   \n",
       "452691               None         NaN            76            76   \n",
       "\n",
       "        passenger_count  trip_distance  fare_amount  extra  mta_tax  \\\n",
       "223196              1.0           0.00        -2.50    0.0     -0.5   \n",
       "66474               1.0           0.31        -3.50   -0.5     -0.5   \n",
       "369089              1.0           0.43        -7.50   -1.0     -0.5   \n",
       "145241              1.0           0.00        -2.50   -0.5     -0.5   \n",
       "443491              NaN           0.00       -29.54    0.0     -0.5   \n",
       "419948              NaN           0.00       -17.75    0.0     -0.5   \n",
       "392578              NaN           0.00       -22.21    0.0     -0.5   \n",
       "406595              NaN           0.00       -16.80    0.0     -0.5   \n",
       "37189               5.0           0.38        -3.50   -1.0     -0.5   \n",
       "452691              NaN           0.03       -33.79    0.0     -0.5   \n",
       "\n",
       "        tip_amount  tolls_amount ehail_fee  improvement_surcharge  \\\n",
       "223196         0.0           0.0      None                   -0.3   \n",
       "66474          0.0           0.0      None                   -0.3   \n",
       "369089         0.0           0.0      None                   -0.3   \n",
       "145241         0.0           0.0      None                   -0.3   \n",
       "443491         0.0           0.0      None                    0.0   \n",
       "419948         0.0           0.0      None                    0.0   \n",
       "392578         0.0           0.0      None                    0.0   \n",
       "406595         0.0           0.0      None                    0.0   \n",
       "37189          0.0           0.0      None                   -0.3   \n",
       "452691         0.0           0.0      None                    0.0   \n",
       "\n",
       "        total_amount  payment_type  trip_type  congestion_surcharge  \n",
       "223196         -3.30           4.0        1.0                   0.0  \n",
       "66474          -4.80           3.0        1.0                   0.0  \n",
       "369089         -9.30           4.0        1.0                   0.0  \n",
       "145241         -3.80           3.0        1.0                   0.0  \n",
       "443491        -30.04           NaN        NaN                   NaN  \n",
       "419948        -18.25           NaN        NaN                   NaN  \n",
       "392578        -22.71           NaN        NaN                   NaN  \n",
       "406595        -17.30           NaN        NaN                   NaN  \n",
       "37189          -5.30           4.0        1.0                   0.0  \n",
       "452691        -34.29           NaN        NaN                   NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_data_df[ny_data_df['fare_amount']<0].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Retain all rows with negative values as the negative values is consistent across all amount columns resulting in negative totals. This may connote a REFUND__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Drop Rows and Fields with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                      0\n",
       "lpep_pickup_datetime          0\n",
       "lpep_dropoff_datetime         0\n",
       "store_and_fwd_flag        89379\n",
       "RatecodeID                89379\n",
       "PULocationID                  0\n",
       "DOLocationID                  0\n",
       "passenger_count           89379\n",
       "trip_distance                 0\n",
       "fare_amount                   0\n",
       "extra                         0\n",
       "mta_tax                       0\n",
       "tip_amount                    0\n",
       "tolls_amount                  0\n",
       "ehail_fee                476386\n",
       "improvement_surcharge         0\n",
       "total_amount                  0\n",
       "payment_type              89379\n",
       "trip_type                 89381\n",
       "congestion_surcharge      89379\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Drop rows with 99.0 and Null values in `RatecodeID` column\n",
    "RatecodeID according to data dictionary has only 6 unique categories - 1.0 - 6.0, 99.0 is invalid and will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RatecodeID\n",
       "1.0     376424\n",
       "5.0       9162\n",
       "2.0        882\n",
       "4.0        319\n",
       "3.0        210\n",
       "99.0         6\n",
       "6.0          4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_data_df['RatecodeID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated data becomes data where RatecodeID is not equal to 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_data_df = ny_data_df[ny_data_df['RatecodeID'] != 99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Find data types and convert to appropriate data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "lpep_pickup_datetime     datetime64[ns]\n",
       "lpep_dropoff_datetime    datetime64[ns]\n",
       "store_and_fwd_flag               object\n",
       "RatecodeID                      float64\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "ehail_fee                        object\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "payment_type                    float64\n",
       "trip_type                       float64\n",
       "congestion_surcharge            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_data_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Numerical to Categorical Columns\n",
    "- RatecodeID\n",
    "- PULocationID\n",
    "- DOLocationID\n",
    "- payment_type\n",
    "- VendorID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style = \"background-color: black\">,\n",
    "        <p><b><font size=\"+2\" color=\"orange\">Function to clean parquet data</font></b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping columns with more than 50% nulls)\n",
      "dropped Index(['ehail_fee'], dtype='object') column\n",
      "cleaning 476386 rows of data\n",
      "dropped 89381 null rows than threshold\n",
      "dropped 4 rows with invalid values in RatecodeID column\n",
      "Raw Parquet data successfully cleaned giving 387005 clean rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./ny_taxi_cleaned_data/cleaned_green_taxi_data.parquet',\n",
       "             VendorID           lpep_pickup_datetime  \\\n",
       " count  387001.000000                         387001   \n",
       " mean        1.833512  2019-10-16 03:48:58.400265216   \n",
       " min         1.000000            2008-10-21 15:52:05   \n",
       " 25%         2.000000            2019-10-08 10:56:00   \n",
       " 50%         2.000000            2019-10-16 11:28:46   \n",
       " 75%         2.000000            2019-10-23 23:13:16   \n",
       " max         2.000000            2019-11-13 08:46:52   \n",
       " std         0.372519                            NaN   \n",
       " \n",
       "                lpep_dropoff_datetime     RatecodeID   PULocationID  \\\n",
       " count                         387001  387001.000000  387001.000000   \n",
       " mean   2019-10-16 04:09:16.739233280       1.100586     105.564030   \n",
       " min              2008-10-21 15:54:26       1.000000       1.000000   \n",
       " 25%              2019-10-08 11:15:39       1.000000      52.000000   \n",
       " 50%              2019-10-16 11:48:58       1.000000      82.000000   \n",
       " 75%              2019-10-23 23:33:46       1.000000     158.000000   \n",
       " max              2019-11-13 08:58:26       6.000000     265.000000   \n",
       " std                              NaN       0.617090      70.105587   \n",
       " \n",
       "         DOLocationID  passenger_count  trip_distance    fare_amount  \\\n",
       " count  387001.000000    387001.000000  387001.000000  387001.000000   \n",
       " mean      130.427040         1.308312       2.683926      12.544457   \n",
       " min         1.000000         0.000000       0.000000    -200.000000   \n",
       " 25%        66.000000         1.000000       1.000000       6.500000   \n",
       " 50%       129.000000         1.000000       1.710000       9.500000   \n",
       " 75%       193.000000         1.000000       3.170000      14.500000   \n",
       " max       265.000000         9.000000     515.890000    2877.500000   \n",
       " std        76.535996         0.967872       3.219951      12.254033   \n",
       " \n",
       "                extra        mta_tax     tip_amount   tolls_amount  \\\n",
       " count  387001.000000  387001.000000  387001.000000  387001.000000   \n",
       " mean        0.402608       0.484681       1.208670       0.153515   \n",
       " min        -4.500000      -0.500000     -80.800000     -12.500000   \n",
       " 25%         0.000000       0.500000       0.000000       0.000000   \n",
       " 50%         0.000000       0.500000       0.000000       0.000000   \n",
       " 75%         0.500000       0.500000       2.000000       0.000000   \n",
       " max         4.500000       0.500000     158.520000     935.500000   \n",
       " std         0.586923       0.093705       2.133939       2.088373   \n",
       " \n",
       "        improvement_surcharge   total_amount   payment_type      trip_type  \\\n",
       " count          387001.000000  387001.000000  387001.000000  387001.000000   \n",
       " mean                0.290699      15.492482       1.454668       1.023295   \n",
       " min                -0.300000    -200.000000       1.000000       1.000000   \n",
       " 25%                 0.300000       8.300000       1.000000       1.000000   \n",
       " 50%                 0.300000      11.800000       1.000000       1.000000   \n",
       " 75%                 0.300000      18.300000       2.000000       1.000000   \n",
       " max                 0.300000    2878.300000       5.000000       2.000000   \n",
       " std                 0.056425      13.743642       0.522707       0.150837   \n",
       " \n",
       "        congestion_surcharge  \n",
       " count         387001.000000  \n",
       " mean               0.451301  \n",
       " min               -2.750000  \n",
       " 25%                0.000000  \n",
       " 50%                0.000000  \n",
       " 75%                0.000000  \n",
       " max                2.750000  \n",
       " std                1.018531  )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "def clean_parquet(raw_data_parquet,\n",
    "                  remove_nulls=True,\n",
    "                  remove_invalids=True,\n",
    "                  null_parts = 14,\n",
    "                  path_to_cleaned_parquet = \"./ny_taxi_cleaned_data/cleaned_green_taxi_data.parquet\"):\n",
    "    \n",
    "    \"\"\"This function cleans a raw data parquet file of invalid and null data and returns a cleaned dataframe\n",
    "    Usage: clean_parquet(raw_data, neg_fare_to_positive=True, remove_negative_values=True)\n",
    "    Args:\n",
    "        raw_data: The raw data parquet to be cleaned\n",
    "        remove_nulls: A boolean value to remove null values from the data\n",
    "        neg_fare_to_positive: A boolean value to convert negative fare to positive\n",
    "        remove_negative_values: A boolean_value to remove negative values from the data\n",
    "        null_parts: This is estimated using raw_data_df.isnull().sum(). This value is used to divide the number of rows\n",
    "        in the dataframe to determine the threshold for removing rows with null values\n",
    "    Returns:\n",
    "        A cleaned dataframe written to parquet file\"\"\"\n",
    "    \n",
    "    raw_data_df = pq.ParquetFile(raw_data_parquet).read().to_pandas()\n",
    "    \n",
    "    print(\"dropping columns with more than 50% nulls)\")\n",
    "    if remove_nulls:\n",
    "        try:\n",
    "       \n",
    "            #drop columns with >50% nulls\n",
    "            fifty_pct_threshold = len(raw_data_df)/2\n",
    "            columns_to_drop = raw_data_df.columns[raw_data_df.isnull().sum() > fifty_pct_threshold]\n",
    "            raw_data_df = raw_data_df.drop(columns=columns_to_drop)\n",
    "            initial_rows = len(raw_data_df)\n",
    "            print(f\"dropped {columns_to_drop} column\")\n",
    "            print(f\"cleaning {initial_rows} rows of data\")\n",
    "\n",
    "            #drop rows with more nulls than threshold\n",
    "            null_rows_threshold = len(raw_data_df)/null_parts\n",
    "            columns_above_threshold = raw_data_df.columns[raw_data_df.isnull().sum() > null_rows_threshold]\n",
    "            raw_data_df = raw_data_df.dropna(subset=columns_above_threshold)\n",
    "            rows_dropped = initial_rows - len(raw_data_df)\n",
    "            print(f\"dropped {rows_dropped} null rows than threshold\")\n",
    "        except Exception as e:\n",
    "            print(f\"An expected error occurred during null removal: {e}\")\n",
    "            raise\n",
    "     \n",
    "    if remove_invalids:\n",
    "        # drop rows with invalid values in RatecodeID column\n",
    "        not_99_df = raw_data_df[raw_data_df['RatecodeID'] != 99]\n",
    "        invalids_removed = len(raw_data_df) - len(not_99_df)\n",
    "        print(f\"dropped {invalids_removed} rows with invalid values in RatecodeID column\")\n",
    "    cleaned_df = not_99_df\n",
    "    os.makedirs(os.path.dirname(path_to_cleaned_parquet), exist_ok=True)\n",
    "    cleaned_df.to_parquet(path_to_cleaned_parquet)\n",
    "    print(f\"Raw Parquet data successfully cleaned giving {len(raw_data_df)} clean rows\")\n",
    "\n",
    "    return path_to_cleaned_parquet, cleaned_df.describe()\n",
    "\n",
    "clean_parquet(\"./ny_taxi_postgres_data/green_tripdata_2019-10.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style = \"background-color: black\">,\n",
    "        <p><b><font size=\"+2\" color=\"orange\">Generate Schema & Create Database Connection</font></b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pandas function converts the dataframe to a Data Definition Language statement and this doesnt create the schema yet but just describes how the table would look in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"green_taxidata_Oct2019\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"lpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"lpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"RatecodeID\" REAL,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"passenger_count\" REAL,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"ehail_fee\" TEXT,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"payment_type\" REAL,\n",
      "  \"trip_type\" REAL,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(ny_data_df,name='green_taxidata_Oct2019')) #name is name of the table in postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a connection to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert `PULocationID` and `DOLocationID` and `VendorID` to Integer and verify schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.types import Integer, Text, DateTime, Float \n",
    "column_types = {'VendorID':Integer,\n",
    "'lpep_pickup_datetime':DateTime,\n",
    "'lpep_dropoff_datetime':DateTime,\n",
    "'store_and_fwd_flag':Text,\n",
    "'RatecodeID':Float,\n",
    "'PULocationID':Integer,\n",
    "'DOLocationID':Integer,\n",
    "'passenger_count':Float,\n",
    "'trip_distance':Float,\n",
    "'fare_amount':Float,\n",
    "'extra':Float,\n",
    "'mta_tax':Float,\n",
    "'tip_amount':Float,\n",
    "'tolls_amount':Float,\n",
    "'ehail_fee':Text,\n",
    "'improvement_surcharge':Float,\n",
    "'total_amount':Float,\n",
    "'payment_type':Float,\n",
    "'trip_type':Float,\n",
    "'congestion_surcharge':Float}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regenerate Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE \"green_taxidata_Oct2019\" (\n",
      "\t\"VendorID\" INTEGER, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" FLOAT, \n",
      "\t\"PULocationID\" INTEGER, \n",
      "\t\"DOLocationID\" INTEGER, \n",
      "\tpassenger_count FLOAT, \n",
      "\ttrip_distance FLOAT, \n",
      "\tfare_amount FLOAT, \n",
      "\textra FLOAT, \n",
      "\tmta_tax FLOAT, \n",
      "\ttip_amount FLOAT, \n",
      "\ttolls_amount FLOAT, \n",
      "\tehail_fee TEXT, \n",
      "\timprovement_surcharge FLOAT, \n",
      "\ttotal_amount FLOAT, \n",
      "\tpayment_type FLOAT, \n",
      "\ttrip_type FLOAT, \n",
      "\tcongestion_surcharge FLOAT\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(ny_data_df,name='green_taxidata_Oct2019',con=engine,dtype=column_types )) #name is name of the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in the column names first to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_data_df.head(n=0).to_sql(name='green_taxidata_Oct2019', con=engine, if_exists='replace',dtype=column_types, index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block\" style = \"background-color: black\">,\n",
    "        <p><b><font size=\"+2\" color=\"orange\">Load data from parquet to Postgres16</font></b></p>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Load parquet data to postgresql16__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below ingests ny_taxi data into postgresql16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchpyarrow.RecordBatch\n",
      "VendorID: int64\n",
      "lpep_pickup_datetime: timestamp[us]\n",
      "lpep_dropoff_datetime: timestamp[us]\n",
      "store_and_fwd_flag: string\n",
      "RatecodeID: double\n",
      "PULocationID: int64\n",
      "DOLocationID: int64\n",
      "passenger_count: double\n",
      "trip_distance: double\n",
      "fare_amount: double\n",
      "extra: double\n",
      "mta_tax: double\n",
      "tip_amount: double\n",
      "tolls_amount: double\n",
      "improvement_surcharge: double\n",
      "total_amount: double\n",
      "payment_type: double\n",
      "trip_type: double\n",
      "congestion_surcharge: double\n",
      "__index_level_0__: int64 loaded , rows:100000 added to record_batches\n",
      "batchpyarrow.RecordBatch\n",
      "VendorID: int64\n",
      "lpep_pickup_datetime: timestamp[us]\n",
      "lpep_dropoff_datetime: timestamp[us]\n",
      "store_and_fwd_flag: string\n",
      "RatecodeID: double\n",
      "PULocationID: int64\n",
      "DOLocationID: int64\n",
      "passenger_count: double\n",
      "trip_distance: double\n",
      "fare_amount: double\n",
      "extra: double\n",
      "mta_tax: double\n",
      "tip_amount: double\n",
      "tolls_amount: double\n",
      "improvement_surcharge: double\n",
      "total_amount: double\n",
      "payment_type: double\n",
      "trip_type: double\n",
      "congestion_surcharge: double\n",
      "__index_level_0__: int64 loaded , rows:100000 added to record_batches\n",
      "batchpyarrow.RecordBatch\n",
      "VendorID: int64\n",
      "lpep_pickup_datetime: timestamp[us]\n",
      "lpep_dropoff_datetime: timestamp[us]\n",
      "store_and_fwd_flag: string\n",
      "RatecodeID: double\n",
      "PULocationID: int64\n",
      "DOLocationID: int64\n",
      "passenger_count: double\n",
      "trip_distance: double\n",
      "fare_amount: double\n",
      "extra: double\n",
      "mta_tax: double\n",
      "tip_amount: double\n",
      "tolls_amount: double\n",
      "improvement_surcharge: double\n",
      "total_amount: double\n",
      "payment_type: double\n",
      "trip_type: double\n",
      "congestion_surcharge: double\n",
      "__index_level_0__: int64 loaded , rows:100000 added to record_batches\n",
      "batchpyarrow.RecordBatch\n",
      "VendorID: int64\n",
      "lpep_pickup_datetime: timestamp[us]\n",
      "lpep_dropoff_datetime: timestamp[us]\n",
      "store_and_fwd_flag: string\n",
      "RatecodeID: double\n",
      "PULocationID: int64\n",
      "DOLocationID: int64\n",
      "passenger_count: double\n",
      "trip_distance: double\n",
      "fare_amount: double\n",
      "extra: double\n",
      "mta_tax: double\n",
      "tip_amount: double\n",
      "tolls_amount: double\n",
      "improvement_surcharge: double\n",
      "total_amount: double\n",
      "payment_type: double\n",
      "trip_type: double\n",
      "congestion_surcharge: double\n",
      "__index_level_0__: int64 loaded , rows:87001 added to record_batches\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "\n",
    "# To load the 1.27million rows into the database, we need to chunk this parquet file using iterators to do this\n",
    "ny_data_parquet = pq.ParquetFile(\"./ny_taxi_cleaned_data/cleaned_green_taxi_data.parquet\")\n",
    "\n",
    "\n",
    "\n",
    "# Create the table schema (only once, outside the loop)\n",
    "for first_batch in ny_data_parquet.iter_batches(batch_size=1):\n",
    "    first_df = first_batch.to_pandas()\n",
    "    \n",
    "    first_df.head(n=0).to_sql(name='green_taxidata_Oct2019', con=engine, if_exists='replace', index=False)\n",
    "    break  # We only need to create the schema once\n",
    "\n",
    "for batch in ny_data_parquet.iter_batches(batch_size=100000):\n",
    "    ny_data = batch.to_pandas()\n",
    "  \n",
    "    ny_data.to_sql(name='green_taxidata_Oct2019', con=engine, if_exists='append',index=False)\n",
    "    #record_batches.append(ny_data)\n",
    "    print(f\"batch{batch} loaded , rows:{len(ny_data)} added to record_batches\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_data = pd.read_csv('./ny_taxi_postgres_data/taxi_zone_lookup.csv')\n",
    "lookup_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "lookup_data.to_sql(name='taxi_zone_lookup_data', con=engine, if_exists='replace') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this exercise we have ingested the parquet data into the database, \n",
    "- Key takeaways:\n",
    "    - we ran postgres using docker\n",
    "    - We connected to this database\n",
    "    - We then ingested the data into the postgres-docker database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-env)",
   "language": "python",
   "name": "ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
